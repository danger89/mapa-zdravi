{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ČLK scraping\n",
    "The aim of this notebook is to scrap data from [ČLK](https://www.lkcr.cz/seznam-lekaru-426.html) website to obtain current data about doctors in Czech republic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = False\n",
    "run_parallel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "from fake_useragent import UserAgent\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import date\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CHROME = '/home/gary/Apps/chromedriver'\n",
    "PATH_INTERMEDIATE = '../../data/intermediate/'\n",
    "PATH_FINAL = '../../data/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fields and districts\n",
    "Obtain all field and districts available on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fields_districts_dicts():\n",
    "    driver = webdriver.Chrome(PATH_CHROME)\n",
    "    driver.get('https://www.lkcr.cz/seznam-lekaru-426.html#seznam')\n",
    "\n",
    "    ## dict of fields - name:value\n",
    "    d_fields = dict()\n",
    "\n",
    "    filterObor = driver.find_element_by_name('filterObor')\n",
    "    options = [x for x in filterObor.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "    for element in options:\n",
    "        if element.text:\n",
    "            d_fields[element.text] = element.get_attribute(\"value\")\n",
    "\n",
    "    ## dict of districts - name:value\n",
    "    d_districts = dict()\n",
    "\n",
    "    filterOkresId = driver.find_elements_by_name('filterOkresId')[-1]\n",
    "\n",
    "    options = [x for x in filterOkresId.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "    for element in options:\n",
    "        if element.text:\n",
    "            d_districts[element.text] = element.get_attribute(\"value\")\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    np.save(PATH_DATA+'dict_districts.npy', d_districts) \n",
    "    np.save(PATH_DATA+'dict_fields.npy', d_fields) \n",
    "    return d_fields, d_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download:\n",
    "    d_fields, d_districts = get_fields_districts_dicts()\n",
    "else:\n",
    "    d_districts = np.load(PATH_INTERMEDIATE+'dict_districts.npy',allow_pickle='TRUE').item()\n",
    "    d_fields = np.load(PATH_INTERMEDIATE+'dict_fields.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Not necessary to run this cell\n",
    "\n",
    "# print('Gmail username and password')\n",
    "# gmailId, passWord = map(str, input().split())\n",
    "# try:\n",
    "#     driver = webdriver.Chrome(PATH_CHROME)\n",
    "#     driver.get(r'https://accounts.google.com/signin/v2/identifier?continue='+\\\n",
    "#     'https%3A%2F%2Fmail.google.com%2Fmail%2F&service=mail&sacu=1&rip=1'+\\\n",
    "#     '&flowName=GlifWebSignIn&flowEntry = ServiceLogin')\n",
    "#     driver.implicitly_wait(15)\n",
    "  \n",
    "#     loginBox = driver.find_element_by_xpath('//*[@id =\"identifierId\"]')\n",
    "#     loginBox.send_keys(gmailId)\n",
    "  \n",
    "#     nextButton = driver.find_elements_by_xpath('//*[@id =\"identifierNext\"]')\n",
    "#     nextButton[0].click()\n",
    "  \n",
    "#     passWordBox = driver.find_element_by_xpath(\n",
    "#         '//*[@id =\"password\"]/div[1]/div / div[1]/input')\n",
    "#     passWordBox.send_keys(passWord)\n",
    "  \n",
    "#     nextButton = driver.find_elements_by_xpath('//*[@id =\"passwordNext\"]')\n",
    "#     nextButton[0].click()\n",
    "  \n",
    "#     print('Login OK')\n",
    "# except:\n",
    "#     print('Login Failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment when run for the first time\n",
    "# # stores all retrieved records\n",
    "# total_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_viewport_size(driver, width, height):\n",
    "    '''\n",
    "        Sets width and height of the webpage. It can help to bypass CAPTCHA\n",
    "    '''\n",
    "    window_size = driver.execute_script(\"\"\"\n",
    "        return [window.outerWidth - window.innerWidth + arguments[0],\n",
    "          window.outerHeight - window.innerHeight + arguments[1]];\n",
    "        \"\"\", width, height)\n",
    "    driver.set_window_size(*window_size)\n",
    "\n",
    "    \n",
    "\n",
    "def chunks(d, SIZE=10):\n",
    "    '''\n",
    "     Split dictionary into chunks of SIZE\n",
    "    '''\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(d), SIZE):\n",
    "        yield {k:d[k] for k in islice(it, SIZE)}\n",
    "            \n",
    "\n",
    "def save_progress(processed_letters, finished_letters):\n",
    "    with open(PATH_INTERMEDIATE+'finished_letters.txt','w') as f:\n",
    "        f.write(str(finished_letters))\n",
    "\n",
    "    np.save(PATH_INTERMEDIATE+'processed_letters.npy', processed_letters) \n",
    "\n",
    "def load_progress():\n",
    "    '''\n",
    "     Load info about already processed substrings in CLK search.\n",
    "     Returns:\n",
    "         processed_letters: already processed substrings\n",
    "         finished_letters: completely processed first letters from the alphabet\n",
    "    '''\n",
    "    import ast\n",
    "    with open(PATH_INTERMEDIATE+'finished_letters.txt','r') as f:\n",
    "        finished_letters = ast.literal_eval(f.read())\n",
    "\n",
    "    processed_letters = np.load(PATH_INTERMEDIATE+'processed_letters.npy',allow_pickle='TRUE').item()\n",
    "    return processed_letters, finished_letters\n",
    "\n",
    "    \n",
    "def get_surname(full_name):\n",
    "    names = full_name.split()\n",
    "    if ',' in names[-2]:\n",
    "        return names[-2][:-1]\n",
    "    else:\n",
    "        return names[-1]   \n",
    "    \n",
    "## ------------------------------------------------------           \n",
    "def obtain_links(d_districts, d_fields):\n",
    "    l_info = [] # general info about doctors\n",
    "    processed_options = []\n",
    "\n",
    "    try:\n",
    "        # iterate over districts\n",
    "        for district_name, district_id in d_districts.items():\n",
    "\n",
    "            # iterate over fields\n",
    "            for field_name, field_id in d_fields.items():\n",
    "\n",
    "                # https://stackoverflow.com/questions/58872451/how-can-i-bypass-the-google-captcha-with-selenium-and-python\n",
    "                # set fake agent\n",
    "                options = Options()\n",
    "                user_agent = UserAgent().random\n",
    "                options.add_argument(f'user-agent={user_agent}')\n",
    "                # TODO check user_agent's validity \n",
    "                driver = webdriver.Chrome(executable_path=PATH_CHROME, chrome_options=options)\n",
    "\n",
    "                # mouseover actions\n",
    "                action_chains = ActionChains(driver)\n",
    "\n",
    "                # randomly change size of the webpage\n",
    "                set_viewport_size(driver, random.randrange(950, 1300), random.randrange(600, 800))\n",
    "\n",
    "                driver.get('https://www.lkcr.cz/seznam-lekaru-426.html#seznam')\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # mouseover to reject cookies\n",
    "                reject = driver.find_element(By.CLASS_NAME, 'cc-nb-reject') #.click()\n",
    "                ActionChains(driver).move_to_element(reject).click().perform()\n",
    "\n",
    "\n",
    "                # select district\n",
    "                wait = WebDriverWait(driver, 2)\n",
    "                select = wait.until(EC.element_to_be_clickable((By.XPATH, \"//select[@name='filterOkresId']\")))\n",
    "                action_chains.move_to_element(select).click().perform()\n",
    "                time.sleep(1)\n",
    "\n",
    "                select_d = Select(select)\n",
    "                select_d.select_by_value(district_id)\n",
    "\n",
    "                # select field of medicine\n",
    "                select = wait.until(EC.element_to_be_clickable((By.NAME, \"filterObor\")))\n",
    "                action_chains.move_to_element(select).click().perform()\n",
    "                time.sleep(1)\n",
    "\n",
    "                select_f = Select(select)\n",
    "                select_f.select_by_value(field_id)\n",
    "\n",
    "                # Confirm chosen options and search\n",
    "                wait.until(EC.element_to_be_clickable((By.NAME, \"do[findLekar]=1\")))\n",
    "                time.sleep(.5)\n",
    "    #             action_chains.move_to_element(search).click().perform()\n",
    "                search = driver.find_element_by_name('do[findLekar]=1')\n",
    "                search.send_keys(Keys.RETURN)\n",
    "    #             search.click()\n",
    "\n",
    "                time.sleep(4)\n",
    "\n",
    "                # Page counter\n",
    "                counter = 0\n",
    "                while True: \n",
    "                    # Stopping criteria\n",
    "                    next_page_text = f'{counter*20+1}-{counter*20+20}'\n",
    "                    if not next_page_text in driver.page_source and not 'Další >>' in driver.page_source:\n",
    "                        break\n",
    "\n",
    "                    driver.get(f'https://www.lkcr.cz/seznam-lekaru-426.html?paging.pageNo={counter}')\n",
    "                    main = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, \"form-clk\"))\n",
    "                    )\n",
    "                    doc_list = main.find_element(by=By.CLASS_NAME, value='seznam-lekaru.item-list')\n",
    "\n",
    "                    for i in doc_list.find_elements(by=By.CLASS_NAME, value='item')[1:]:\n",
    "                        info = i.text.split('\\n')[:-1]\n",
    "                        link = i.find_element_by_css_selector('a').get_attribute('href')\n",
    "                        info = [link, district_name, field_name] + info \n",
    "                        l_info.append(info)\n",
    "\n",
    "                    # next page\n",
    "                    counter += 1\n",
    "\n",
    "                driver.close()\n",
    "\n",
    "    finally:\n",
    "        return l_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_parallel = False\n",
    "\n",
    "# if not run_parallel:\n",
    "#     ## Sequential run\n",
    "#     x = obtain_links(d_districts, d_fields)\n",
    "#     total_info.append(x)\n",
    "\n",
    "# else:\n",
    "#     ## Parallel run\n",
    "#     n_chunks = 10\n",
    "\n",
    "#     dist_chunks = list(chunks(d_districts, round(len(d_districts)/n_chunks)))\n",
    "#     key = 'alergologie a klinická imunologie'\n",
    "\n",
    "#     res_list = Parallel(n_jobs=n_chunks)(delayed(obtain_links)(dist_chunks[x], {key:d_fields[key]}) for x in range(n_chunks))\n",
    "#     total_info += res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check how many pages the letter has (if >= 50 need to divide into smaller chunks)\n",
    "# # processed_letters = dict()\n",
    "# processed_letters, finished_letters = load_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_links_by_name(prefix='', start_pos=0, end_pos=None):\n",
    "    ## Search by name\n",
    "    '''\n",
    "     Obtain urls by surnames' prefix, you can also specify starting position for following letter (eg. 0 = a, 4 = e etc.)\n",
    "     Return:\n",
    "         l_info: scrapped info\n",
    "         processed_letters: dict with info how many pages prefixes have\n",
    "    '''\n",
    "    \n",
    "    l_info = [] # general info about doctors\n",
    "    processed_letters = dict()\n",
    "\n",
    "    letters = string.ascii_lowercase[start_pos:]\n",
    "    if end_pos:\n",
    "        letters = letters[:end_pos-start_pos+1]\n",
    "        \n",
    "    try:\n",
    "\n",
    "        for letter in letters:\n",
    "            driver = webdriver.Chrome(executable_path=PATH_CHROME)\n",
    "\n",
    "            # Randomly change size of the webpage\n",
    "            set_viewport_size(driver, random.randrange(950, 1300), random.randrange(650, 900))\n",
    "\n",
    "            driver.get('https://www.lkcr.cz/seznam-lekaru-426.html#seznam')\n",
    "\n",
    "            time.sleep(1)\n",
    "            \n",
    "            try:\n",
    "                driver.find_element(By.CLASS_NAME, 'cc-nb-reject').click()\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "            search = driver.find_element_by_name('filterPrijmeni')\n",
    "            search.send_keys(prefix + letter +'%')\n",
    "            search.send_keys(Keys.RETURN)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            # Page counter\n",
    "            counter = 0\n",
    "            while True: \n",
    "                # Stopping criteria\n",
    "                next_page_text = f'{counter*20+1}-{counter*20+20}'\n",
    "                if not (next_page_text in driver.page_source or 'Další&nbsp;&gt;&gt;' in driver.page_source):\n",
    "                    break\n",
    "\n",
    "                driver.get(f'https://www.lkcr.cz/seznam-lekaru-426.html?paging.pageNo={counter}')\n",
    "                main = WebDriverWait(driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"form-clk\"))\n",
    "                )\n",
    "                doc_list = main.find_element(by=By.CLASS_NAME, value='seznam-lekaru.item-list')\n",
    "\n",
    "                for i in doc_list.find_elements(by=By.CLASS_NAME, value='item')[1:]:\n",
    "                    info = i.text.split('\\n')[:-1]\n",
    "                    link = i.find_element_by_css_selector('a').get_attribute('href')\n",
    "                    info = [link] + info \n",
    "                    l_info.append(info)\n",
    "\n",
    "                # Next page\n",
    "                counter += 1\n",
    "\n",
    "            processed_letters[prefix + letter] = counter\n",
    "            driver.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'[{prefix + letter}] Error occured:', e)\n",
    "        \n",
    "    finally:\n",
    "        return l_info, processed_letters\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letters = doctors.surname.apply(lambda x: x[0]).unique()\n",
    "# letters.sort()\n",
    "\n",
    "# for letter in letters:\n",
    "#     recs = doctors[doctors.surname.apply(lambda x: x[0] == letter)].sort_values('surname')\n",
    "#     n_recs = recs.shape[0]\n",
    "#     last_rec = recs.iloc[-1, 1] #tail(1).surname\n",
    "#     if not letter in finished_letters:\n",
    "#         print(f'[{letter}] total: {n_recs}, {last_rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '' \n",
    "\n",
    "if not prefix in finished_letters:\n",
    "    l_info, new_processed_letters = obtain_links_by_name(prefix, start_pos=8, end_pos=8)\n",
    "    \n",
    "    total_info += l_info\n",
    "    processed_letters = {**processed_letters, **new_processed_letters}\n",
    "#     print(total_info[-1])\n",
    "#     print(processed_letters)\n",
    "    \n",
    "else:\n",
    "    print(f'Prefix [{prefix + letter}] already finished.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s', 'a', 'b', 'o', 'i', 'x', 'v', 'l', 'm', 'j', 'g', 't', 'ch', 'u', 'z', 'r', 'f', 'c', 'q', 'd', 'n', 'k', 'e', 'w', 'y', 'p', 'h'}\n"
     ]
    }
   ],
   "source": [
    "# print(processed_letters)\n",
    "# finished_letters = set()\n",
    "\n",
    "# for letter, pages in processed_letters.items():\n",
    "#     if 0 < pages < 50:\n",
    "#         finished_letters.add(letter)\n",
    "        \n",
    "finished_letters.add(prefix)\n",
    "\n",
    "print(finished_letters)\n",
    "\n",
    "\n",
    "## SAVE PROGRESS \n",
    "save_progress(processed_letters, finished_letters)\n",
    "# processed_letters, finished_letters = load_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not set(string.ascii_lowercase).difference(finished_letters), set(string.ascii_lowercase).difference(finished_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_info(total_info):\n",
    "    '''\n",
    "     Parses values from list and converts it into the pd.DataFrame\n",
    "     Returns: pd.DataFrame\n",
    "    '''\n",
    "\n",
    "    # columns\n",
    "    n_cols = max(map(len, total_info))\n",
    "    doctors = pd.DataFrame(total_info, columns=['url', 'name', *[f'workplace{x}' for x in range(1, n_cols-1)]])\n",
    "    # surname\n",
    "    doctors['surname'] = doctors.name.apply(get_surname)\n",
    "    doctors.surname = doctors.surname.apply(unidecode.unidecode)\n",
    "    doctors.surname = doctors.surname.apply(lambda x: x.lower())\n",
    "    doctors.loc[doctors.name == 'MUDr. Karin Boušová , Ph.D.', 'surname'] = 'Boušová'\n",
    "\n",
    "    doctors.loc[(doctors.name == 'Nedal M. H. Abuasad') & (doctors.url.isna()), 'url'] = 'https://www.lkcr.cz/seznam-lekaru?filterId=MTE2MDU4NTE4NSwsTmVkYWwgTS4gSC4sLEFidWFzYWQ%3D&do[load]=1'\n",
    "\n",
    "    return doctors\n",
    "\n",
    "doctors = parse_info(total_info)\n",
    "# save\n",
    "doctors.to_csv(PATH_INTERMEDIATE+ 'doctors_alphabetical.csv', index=False, header=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56149, 5), (62242, 5))"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drops duplicates by url\n",
    "doctors_no_dupl = pd.read_csv(PATH_INTERMEDIATE + 'doctors_alphabetical.csv')\n",
    "doctors_no_dupl = doctors_no_dupl.drop_duplicates('url', keep='last')\n",
    "doctors_no_dupl.to_csv(PATH_INTERMEDIATE + 'doctors_alphabetical_nd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Benešov', 'Beroun', 'Blansko', 'Brno-město', 'Brno-venkov', 'Bruntál', 'Břeclav', 'Česká Lípa', 'České Budějovice', 'Český Krumlov', 'Děčín', 'Domažlice', 'Frýdek-Místek', 'Havlíčkův Brod', 'Hodonín', 'Hradec Králové', 'Cheb', 'Chomutov', 'Chrudim', 'Jablonec nad Nisou', 'Jeseník', 'Jičín', 'Jihlava', 'Jindřichův Hradec', 'Karlovy Vary', 'Karviná', 'Kladno', 'Klatovy', 'Kolín', 'Kroměříž', 'Kutná Hora', 'Liberec', 'Litoměřice', 'Louny', 'Mělník', 'Mladá Boleslav', 'Most', 'Náchod', 'Nový Jičín', 'Nymburk', 'Olomouc', 'Opava', 'Ostrava-město', 'Pardubice', 'Pelhřimov', 'Písek', 'Plzeň-jih', 'Plzeň-město', 'Plzeň-sever', 'Praha hl.m.', 'Praha-východ', 'Praha-západ', 'Prachatice', 'Prostějov', 'Přerov', 'Příbram', 'Rakovník', 'Rokycany', 'Rychnov nad Kněžnou', 'Semily', 'Sokolov', 'Strakonice', 'Svitavy', 'Šumperk', 'Tábor', 'Tachov', 'Teplice', 'Trutnov', 'Třebíč', 'Uherské Hradiště', 'Ústí nad Labem', 'Ústí nad Orlicí', 'Vsetín', 'Vyškov', 'Zlín', 'Znojmo', 'Žďár nad Sázavou'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_districts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts x fields:  9009 x\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'processed_letters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d9aa08c46711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Districts x fields: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_districts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alphabet:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_letters' is not defined"
     ]
    }
   ],
   "source": [
    "print('Districts x fields: ', len(d_districts) * len(d_fields), 'x')\n",
    "print('Alphabet:', len(processed_letters), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>workplace1</th>\n",
       "      <th>workplace2</th>\n",
       "      <th>surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=MTE...</td>\n",
       "      <td>MUDr. Miroslav Baader</td>\n",
       "      <td>Liberec 1</td>\n",
       "      <td>None</td>\n",
       "      <td>baader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Jana Baarová</td>\n",
       "      <td>Kopřivnice 1</td>\n",
       "      <td>None</td>\n",
       "      <td>baarova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Monika Baarová</td>\n",
       "      <td>Hradec Králové</td>\n",
       "      <td>None</td>\n",
       "      <td>baarova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Věra Baarová</td>\n",
       "      <td>Havířov 1</td>\n",
       "      <td>None</td>\n",
       "      <td>baarova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Vladimíra Baarová</td>\n",
       "      <td>Klatovy</td>\n",
       "      <td>None</td>\n",
       "      <td>baarova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62237</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Marie Mizerová</td>\n",
       "      <td>Olomouc 9</td>\n",
       "      <td>None</td>\n",
       "      <td>mizerova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62238</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=MTE...</td>\n",
       "      <td>MUDr. Jan Mizner</td>\n",
       "      <td>Praha 10</td>\n",
       "      <td>None</td>\n",
       "      <td>mizner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62239</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=MTE...</td>\n",
       "      <td>MUDr. Petr Mizner</td>\n",
       "      <td>Praha 5</td>\n",
       "      <td>None</td>\n",
       "      <td>mizner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62240</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Barbora Miznerová</td>\n",
       "      <td>Opava 5</td>\n",
       "      <td>None</td>\n",
       "      <td>miznerova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62241</td>\n",
       "      <td>https://www.lkcr.cz/seznam-lekaru?filterId=NTE...</td>\n",
       "      <td>MUDr. Eliška Mižičková</td>\n",
       "      <td>Olomouc</td>\n",
       "      <td>None</td>\n",
       "      <td>mizickova</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://www.lkcr.cz/seznam-lekaru?filterId=MTE...   \n",
       "1      https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "2      https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "3      https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "4      https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "...                                                  ...   \n",
       "62237  https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "62238  https://www.lkcr.cz/seznam-lekaru?filterId=MTE...   \n",
       "62239  https://www.lkcr.cz/seznam-lekaru?filterId=MTE...   \n",
       "62240  https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "62241  https://www.lkcr.cz/seznam-lekaru?filterId=NTE...   \n",
       "\n",
       "                          name      workplace1 workplace2    surname  \n",
       "0        MUDr. Miroslav Baader       Liberec 1       None     baader  \n",
       "1           MUDr. Jana Baarová    Kopřivnice 1       None    baarova  \n",
       "2         MUDr. Monika Baarová  Hradec Králové       None    baarova  \n",
       "3           MUDr. Věra Baarová       Havířov 1       None    baarova  \n",
       "4      MUDr. Vladimíra Baarová         Klatovy       None    baarova  \n",
       "...                        ...             ...        ...        ...  \n",
       "62237     MUDr. Marie Mizerová       Olomouc 9       None   mizerova  \n",
       "62238         MUDr. Jan Mizner        Praha 10       None     mizner  \n",
       "62239        MUDr. Petr Mizner         Praha 5       None     mizner  \n",
       "62240  MUDr. Barbora Miznerová         Opava 5       None  miznerova  \n",
       "62241   MUDr. Eliška Mižičková         Olomouc       None  mizickova  \n",
       "\n",
       "[62242 rows x 5 columns]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap obtained links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(rec, name):\n",
    "    with open(PATH_INTERMEDIATE + name + '.json', \"w\") as outfile:\n",
    "        json.dump(rec, outfile)\n",
    "        \n",
    "## ------------------------------------------\n",
    "\n",
    "def parse_doctor_tables(tables):\n",
    "    '''\n",
    "        Parse tables in records' url\n",
    "        Input[tables]: WebElelement\n",
    "        Output[d_detail]: dict\n",
    "    '''\n",
    "    d_detail = dict()\n",
    "    \n",
    "    # evidence number\n",
    "    ev_num = tables[0].find_element(by=By.CLASS_NAME, value='evidencni-cislo').text.split()[-1]\n",
    "    d_detail['Evidenční číslo'] = ev_num\n",
    "\n",
    "    ## first + second table\n",
    "    for table in tables[:2]:\n",
    "        for row in table.find_elements_by_css_selector('tr'):\n",
    "            cell = row.find_elements_by_css_selector('td')\n",
    "            key = cell[0].text\n",
    "            values = cell[1].text.split('\\n')\n",
    "            values = values if len(values)>1 else values[0]\n",
    "            d_detail[key] = values\n",
    "    \n",
    "    ## 3+ table (workplaces)\n",
    "    workplaces = []\n",
    "    for workplace in tables[2:]:\n",
    "        d_workplace = dict()\n",
    "        for row in workplace.find_elements_by_css_selector('tr'):\n",
    "            cell = row.find_elements_by_css_selector('td')\n",
    "            key = cell[0].text\n",
    "            values = cell[1].text.split('\\n')\n",
    "            values = values if len(values)>1 else values[0]\n",
    "            d_workplace[key] = values\n",
    "\n",
    "        workplaces.append(d_workplace)\n",
    "\n",
    "    d_detail['Pracoviště'] = workplaces\n",
    "    \n",
    "    return d_detail\n",
    "\n",
    "## ------------------------------------------\n",
    "def remove_asterisks(tables):\n",
    "    new_tables = []\n",
    "    for table in tables:\n",
    "        if not '*' in table.text:\n",
    "            new_tables.append(table)\n",
    "\n",
    "    return new_tables\n",
    "\n",
    "def get_doctor_detail(url, driver):\n",
    "    '''\n",
    "        Return detail info about doctors.\n",
    "        Input[url]: str, CLK url \n",
    "        Output[d_detail]: dict, info about doctor\n",
    "    '''\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # due to the bug in the opening\n",
    "#         driver.refresh()\n",
    "  \n",
    "        # load main content\n",
    "        main = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"detail-lekare\"))\n",
    "        )\n",
    "        \n",
    "        # basic info\n",
    "        tables = main.find_elements(by=By.CLASS_NAME, value='text-box-lekar')\n",
    "        tables = remove_asterisks(tables)\n",
    "        d_detail = parse_doctor_tables(tables)\n",
    "\n",
    "        # name\n",
    "        name = main.find_element(by=By.CLASS_NAME, value='jmeno-lekare').text\n",
    "        d_detail['Jméno'] = name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'[{url}] Error occured:', e)\n",
    "    finally:\n",
    "#         driver.close()\n",
    "        return d_detail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_doctors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... 5000/56149\n",
      ".......... 10000/56149\n",
      ".......... 15000/56149\n",
      ".......... 20000/56149\n",
      ".......... 25000/56149\n",
      ".......... 30000/56149\n",
      ".......... 35000/56149\n",
      ".......... 40000/56149\n",
      ".......... 45000/56149\n",
      ".......... 50000/56149\n",
      ".......... 55000/56149\n",
      ".. Finished!\n"
     ]
    }
   ],
   "source": [
    "## Loop for downloading websites\n",
    "cnt = 1\n",
    "n_url = doctors_no_dupl.url.nunique()\n",
    "try:\n",
    "    driver = webdriver.Chrome(PATH_CHROME)\n",
    "    driver.get('https://www.lkcr.cz/seznam-lekaru-426.html#seznam')\n",
    "\n",
    "    for url in doctors_no_dupl.url.unique():\n",
    "        if cnt % 500 == 0:\n",
    "            print('.', end='')\n",
    "        if cnt % 5000 == 0:\n",
    "            print(f' {cnt}/{n_url}')    \n",
    "        cnt += 1\n",
    "\n",
    "        d_detail = get_doctor_detail(url, driver)\n",
    "        d_detail['url'] = url\n",
    "        l_doctors.append(d_detail)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'[{url}] Error occured:', e)\n",
    "        \n",
    "finally:\n",
    "    print(' Finished!')\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json(l_doctors, 'doctors_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Evidenční číslo', 'Vysoká škola', 'Rok promoce',\n",
      "       'Diplom celoživotního vzdělávání', 'Pracoviště', 'Jméno', 'url',\n",
      "       'Dosažená odbornost', 'K výkonu soukromé praxe a lektora v oboru',\n",
      "       'Pro výkon funkce vedoucího lékaře a primáře v oboru',\n",
      "       'Funkční licence pro léčebnou metodu'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_INTERMEDIATE + 'doctors_all.json') as f:\n",
    "    data = json.load(f)    \n",
    "\n",
    "doctors = pd.json_normalize(data)\n",
    "print(doctors.columns)\n",
    "doctors.columns = ['_id', 'university', 'graduated_year', 'lifelong_studies',\n",
    "                   'workplace', 'doctor_name', 'doctor_url', 'medical_specialty',\n",
    "                   'private_practice', 'leading_doctor_licence', 'method_of_treatment_licence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors = doctors[doctors['doctor_name'] != ''].reset_index(drop=True)\n",
    "\n",
    "# fix graduated years\n",
    "doctors.loc[doctors.graduated_year == '9819', 'graduated_year'] = '1998'\n",
    "doctors.loc[doctors.graduated_year == '', 'graduated_year'] = np.nan\n",
    "doctors.loc[doctors.graduated_year == '0', 'graduated_year'] = np.nan\n",
    "doctors.loc[~doctors.graduated_year.isna(), 'graduated_year'] = doctors.loc[~doctors.graduated_year.isna(), 'graduated_year'].apply(int)\n",
    "\n",
    "# fix university\n",
    "doctors.loc[doctors.university == '', 'university'] = np.nan\n",
    "doctors.loc[doctors.university == 'neuvedena', 'university'] = np.nan\n",
    "\n",
    "# fix lifelong studies\n",
    "doctors['lifelong_studies'] = np.where(doctors['lifelong_studies'] == 'ano', True, False)\n",
    "\n",
    "# workplaces\n",
    "doctors['n_doctor_workplaces'] = doctors.workplace.apply(len)\n",
    "doctors.loc[~doctors.workplace.apply(bool), 'workplace'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "# estimate an age based on students age at the time they graduated and their probabilities\n",
    "students = pd.read_csv(PATH_FINAL+'students.csv', index_col=0)\n",
    "\n",
    "dr = students[(students['graduated'] == True) & (students.major == 'Všeobecné lékařství')][['graduated', 'major', 'age_end']]\n",
    "\n",
    "ages = dr.age_end.value_counts().reset_index()\n",
    "ages.columns = ['age','count']\n",
    "n_records = sum(ages['count'])\n",
    "ages['p'] = ages['count'] / n_records\n",
    "# ages.head()\n",
    "\n",
    "\n",
    "random_age = np.random.choice(ages['age'], p=ages['p'], size=doctors.shape[0])\n",
    "doctors['graduated_age_estimate'] = random_age\n",
    "doctors['graduated_age_estimate'] = doctors['graduated_age_estimate'].apply(round)\n",
    "doctors['age_estimate'] = doctors['graduated_age_estimate'] + (date.today().year - doctors['graduated_year']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors = doctors.explode('workplace').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_wp_df = doctors['workplace'].apply(pd.Series).drop([0], axis=1)\n",
    "doctors_wp_df = doctors_wp_df[['Název zdravotnického zařízení:', 'Název pracoviště:', 'Adresa pracoviště:']]\n",
    "doctors_wp_df.columns = ['workplace_name', 'workplace_hospital_ward', 'workplace_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_df = pd.concat([doctors.drop(['workplace'], axis=1), doctors_wp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse address\n",
    "\n",
    "def get_zip_code(address):\n",
    "    idx = re.search(r\"\\d\\d\\d\\d\\d\", address)\n",
    "    if not idx:\n",
    "        return np.nan\n",
    "    idx = idx.start()\n",
    "    return int(address[idx:idx+5])\n",
    "\n",
    "def get_street(address):\n",
    "    idx = re.search(r\", \\d\\d\\d\", address)    \n",
    "    idx = idx.start()\n",
    "    return address[:idx]\n",
    "\n",
    "def get_city(address):\n",
    "    idx = re.search(r\"\\d\\d\\d\\d\\d \", address)\n",
    "    if not idx:\n",
    "        return np.nan\n",
    "    idx = idx.end()\n",
    "    return address[idx:]\n",
    "        \n",
    "\n",
    "wp_na = doctors_df['workplace_address'].isna()\n",
    "\n",
    "doctors_df['zip_code'] = doctors_df[~wp_na].workplace_address.apply(get_zip_code)\n",
    "doctors_df['street'] = doctors_df[~wp_na].workplace_address.apply(get_street)\n",
    "doctors_df['city'] = doctors_df[~wp_na].workplace_address.apply(get_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of companies' workplaces\n",
    "doctors_df_unique = doctors_df.drop_duplicates(['workplace_name', 'workplace_hospital_ward', 'workplace_address'])\n",
    "n_workplaces = doctors_df_unique.groupby(['workplace_name', 'workplace_hospital_ward']).size().reset_index(name='n_workplaces')\n",
    "doctors_df = pd.merge(doctors_df, n_workplaces, how='left')\n",
    "\n",
    "# number of doctors in workplace\n",
    "doctors_df_unique = doctors_df.drop_duplicates(['workplace_name', 'workplace_hospital_ward', '_id'])\n",
    "n_doctors_in_workplace = doctors_df_unique.groupby(['workplace_name', 'workplace_hospital_ward']).size().reset_index(name='n_doctors_in_workplace')\n",
    "doctors_df = pd.merge(doctors_df, n_doctors_in_workplace, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix uni\n",
    "\n",
    "def uni_abbreviation(uni):\n",
    "    return {\n",
    "        '1. LF Univerzity Karlovy v Praze' : '1LFUK',\n",
    "        '2. LF Univerzity Karlovy v Praze' : '2LFUK',\n",
    "        '3. LF Univerzity Karlovy v Praze' : '3LFUK',\n",
    "        'LF Univerzity Karlovy v Plzni' : 'PLUK',\n",
    "        'LF Univerzity Karlovy v Hradci Králové' : 'HKUK',\n",
    "        'LF Masarykovy Univerzity v Brně' : 'MUNI',\n",
    "        'LF Univerzity Palackého v Olomouci' : 'UPOL',\n",
    "        'LF Ostravské univerzity v Ostravě' : 'OVA',\n",
    "        'Vojenská lékařská akademie v Hradci Králové' : 'UNOB',\n",
    "        'zahraniční lékařská fakulta' : 'ABROAD'\n",
    "    }.get(uni, np.nan)\n",
    "\n",
    "uni_na = doctors_df.university.isna()\n",
    "doctors_df.loc[~uni_na, 'university'] = doctors_df[~uni_na].university.apply(uni_abbreviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_df.loc[(doctors_df.graduated_year == 1194), 'graduated_year'] = 1994\n",
    "doctors_df.loc[(doctors_df.graduated_year < 1945), 'graduated_year'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doctors_df = pd.read_csv(PATH_FINAL+'doctors.csv', index_col=0)\n",
    "# doctors_df = doctors_df.explode('medical_specialty').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fields_unif = {\n",
    "    'epidemiologie': 'hygiena a epidemiologie',\n",
    "    'hygiena všeobecná a komunální': 'hygiena a epidemiologie',\n",
    "    'hygiena obecná a komunální': 'hygiena a epidemiologie',\n",
    "    'hygiena práce a nemoci z povolání': 'hygiena a epidemiologie',\n",
    "    'hygiena záření': 'hygiena a epidemiologie',\n",
    "    'hygiena výživy a předmětů běžného užívání': 'hygiena a epidemiologie',\n",
    "    'hygiena výživy ': 'hygiena a epidemiologie',\n",
    "    'všeobecné lékařství': 'všeobecné praktické lékařství',\n",
    "    'praktické lékařství pro dospělé': 'všeobecné praktické lékařství',\n",
    "    'dětské lékařství': 'pediatrie',\n",
    "    'praktické lékařství pro děti a dorost': 'pediatrie',\n",
    "    'dorostové lékařství': 'pediatrie',\n",
    "    'dětská onkologie a hematoonkologie': 'dětská onkologie a hematologie',\n",
    "    'dětská gynekologie': 'gynekologie dětí a dospívajících',\n",
    "    'hygiena dětí a dorostu': 'dětská hygiena',\n",
    "    'dětská a dorostová psychiatrie': 'dětská psychiatrie',\n",
    "    'diabetologie a endokrinologie': 'endokrinologie a diabetologie',\n",
    "    'endokrinologie': 'endokrinologie a diabetologie',\n",
    "    'diabetologie': 'endokrinologie a diabetologie',\n",
    "    'audiologie a foniatrie': 'foniatrie',\n",
    "    'audiologie': 'foniatrie',\n",
    "    'stomatologická chirurgie': 'maxilofaciální chirurgie',\n",
    "    'úrazová chirurgie (traumatologie)': 'úrazová chirurgie',\n",
    "    'traumatologie': 'úrazová chirurgie',\n",
    "    'otorinolaryngologie': 'otorinolaryngologie a chirurgie hlavy a krku',\n",
    "    'patologická anatomie': 'patologie',\n",
    "    'léčení alkoholismu a jiných toxikomanií': 'návykové nemoci',\n",
    "    'paliativní medicína a léčba bolesti': 'paliativní medicína',\n",
    "    'plicní chirurgie': 'hrudní chirurgie',\n",
    "    'traumatologie pohybového ústrojí': 'ortopedie a traumatologie pohybového ústrojí',\n",
    "    'ortopedie': 'ortopedie a traumatologie pohybového ústrojí',\n",
    "    'ortopedická protetika': 'ortopedie a traumatologie pohybového ústrojí',\n",
    "    'přenosné nemoci': 'infekční lékařství',\n",
    "    '\"fyziatrie, balneologie a léčebná rehabilitace\"': 'rehabilitační a fyzikální medicína',\n",
    "    'hyperbarická a letecká medicína': 'hyperbarická medicína a oxygenoterapie',\n",
    "    'letecké lékařství': 'hyperbarická medicína a oxygenoterapie',\n",
    "    'radiodiagnostika': 'radiologie a zobrazovací metody',\n",
    "    'radioterapie': 'radiační onkologie',\n",
    "    'anesteziologie a resuscitace': 'anesteziologie a intenzivní medicína',\n",
    "    'hematolologie a transfuzní služba': 'hematologie a transfuzní lékařství',\n",
    "    'interní lékařství': 'vnitřní lékařství',\n",
    "    'posudkové lékařství': 'soudní lékařství',\n",
    "    'mikrobiologie': 'lékařská mikrobiologie',\n",
    "    'mikrobiologie životního prostředí': 'lékařská mikrobiologie',\n",
    "    'perinatologie': 'perinatologie a fetomaternální medicína',\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_fields(fields):\n",
    "    if fields is np.NaN:\n",
    "        return np.NaN\n",
    "    if isinstance(fields, list):\n",
    "        converted = []\n",
    "        for x in fields:\n",
    "            converted.append(d_fields_unif.get(x, x))\n",
    "        return list(set(converted))\n",
    "    else:\n",
    "        return [d_fields_unif.get(fields, fields)]\n",
    "\n",
    "doctors_df['medical_specialty'] = doctors_df['medical_specialty'].apply(convert_fields)\n",
    "doctors_df['private_practice'] = doctors_df['private_practice'].apply(convert_fields)\n",
    "doctors_df['leading_doctor_licence'] = doctors_df['leading_doctor_licence'].apply(convert_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_df.to_csv(PATH_FINAL+'doctors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_df = pd.read_csv(PATH_FINAL+'doctors.csv', index_col=0)\n",
    "dentists_df = pd.read_csv(PATH_FINAL+'dentists.csv', index_col=0)\n",
    "docs_total = pd.concat([doctors_df, dentists_df])\n",
    "\n",
    "docs_total.to_csv(PATH_FINAL+'doctors_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only in doctors.csv: {'university', 'workplace_hospital_ward', 'lifelong_studies', 'leading_doctor_licence', 'graduated_year', 'age_estimate', 'method_of_treatment_licence'}\n",
      "Only in dentists.csv: {'area', 'IC', 'workplace_url'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Only in doctors.csv: {set(doctors_df.columns).difference(set(dentists_df.columns))}')\n",
    "print(f'Only in dentists.csv: {set(dentists_df.columns).difference(set(doctors_df.columns))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELENIUM\n",
    "https://www.youtube.com/watch?v=b5jt2bhSeXs&ab_channel=TechWithTim\n",
    "\n",
    "https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement\n",
    "\n",
    "https://stackoverflow.com/questions/58872451/how-can-i-bypass-the-google-captcha-with-selenium-and-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('vzd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08ea57a3b14e8972cb95441d2d329063d79c5206768d2acc286d89f92e5e608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
